<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Maciek's blog</title><link>https://blog.mmakowski.com/tags/machine-learning/</link><description>Recent content in machine learning on Maciek's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 27 Aug 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.mmakowski.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>KDD 2018: The Rest</title><link>https://blog.mmakowski.com/technology/kdd-2018-the-rest/</link><pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/kdd-2018-the-rest/</guid><description>KDD 2018 was intense. Workshops and keynotes started at 8 AM and the poster sessions were runing until 9 PM. There was a dozen tracks running in parallel, so choosing the session to attend was hard – there was always something else potentially interesting going on at the same time. For the first two days I tried to pay close attention and write up comprehensible notes from the tutorials and workshops, but that was not sustainable, so from the third day on I sat back, relaxed, listened more, wrote less.</description></item><item><title>KDD 2018: Quantum Machine Learning</title><link>https://blog.mmakowski.com/technology/kdd-2018-quantum-machine-learning/</link><pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/kdd-2018-quantum-machine-learning/</guid><description>It must be an exciting time for quantum computing researches. Up until a few years ago all work in this domain was about building theoretical models of what will be possible once we have a quantum computer. Today, a number of companies have built and made available physical quantum computers. So far those are toy-size, proofs of concept, with no practical application, but this gives hope that practical devices will become available in a few years’ time, so wider community should take notice.</description></item><item><title>KDD 2018: Common Model Infrastructure</title><link>https://blog.mmakowski.com/technology/kdd-2018-common-model-infrastructure/</link><pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/kdd-2018-common-model-infrastructure/</guid><description>Go away and have fun building models like there is no tomorrow. After all, we do the real creative work, innovation, science. The software and operations engineers just deal with the plumbing and have an easy, predictable job compared to us, data scientists. This might not be a mindset many would admit to, but subconciously we do tend to underestimate the importance of others’ jobs. To be fair, the enginneering and operations folks are not much better in this respect – everyone tends to think their work is more demanding and output more valuable than average.</description></item><item><title>KDD 2018: Explainable Models for Healthcare AI</title><link>https://blog.mmakowski.com/technology/kdd-2018-explainable-models-for-healthcare-ai/</link><pubDate>Mon, 20 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/kdd-2018-explainable-models-for-healthcare-ai/</guid><description>The Explainable Models for Healthcare AI tutorial was presented by a trio from KenSci Inc. that included a data scientist and a clinician. The premise of the session was that explainability is particularly important in healthcare applications of machine learning, due to the far-reaching consequences of decisions, high cost of mistakes, fairness and compliance requirements. The tutorial walked through a number of aspects of interpretability and discussed techniques that can be applied to explain model predictions.</description></item><item><title>KDD 2018: Deep Learning for Computational Health</title><link>https://blog.mmakowski.com/technology/kdd-2018-deep-learning-for-computational-health/</link><pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/kdd-2018-deep-learning-for-computational-health/</guid><description>The Deep Learnig for Computational Health tutorial was presented by Jimeng Sun, Edward Choi and Cao Xiao. With the electronic health record (EHR) data comprising free text, structured codes, time series and images, a wide range of deep learning techniques has been successfully applied to their analysis. The presenters focussed on capturing the information about the sequence of patient’s visits, interpretability of models and representation learning for textual and structured data.</description></item><item><title>Precision confidence interval in the presence of unreliable labels</title><link>https://blog.mmakowski.com/technology/precision-confidence-interval-in-the-presence-of-unreliable-labels/</link><pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/precision-confidence-interval-in-the-presence-of-unreliable-labels/</guid><description>Consider a binary classifier that produced the following counts of true positives (TP) and false positives (FP) on test data.
tp_observed = 5285 fp_observed = 3184 We would like to know the 95% confidence interval for precision metric of this classifier. Goutte and Gaussier showed that precision follows the Beta distribution with the counts of TPs and FPs as parameters, adjusted for prior. We will use uniform prior, $Beta(1,1)$.
import pymc3 as pm with pm.</description></item><item><title>RAPIDS 2018</title><link>https://blog.mmakowski.com/technology/rapids-2018/</link><pubDate>Thu, 19 Jul 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/rapids-2018/</guid><description>Having for the last year incessantly worried about the day when someone asks how we achieved a certain model metric, and not being able to answer or even replicate the result, I found the subject of Reproducibility and Provenance in Data Science mini-conference – RAPIDS in short – much to my interest. The solutions to the provenance tracking and reproducibility problem I came up with so far were hand-cranked and built on top of tools whose selection was influenced more by my personal preferences than the prevailing industry practices.</description></item><item><title>Machine Learning in Three Pages</title><link>https://blog.mmakowski.com/technology/machine-learning-in-three-pages/</link><pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/machine-learning-in-three-pages/</guid><description>A supervised machine learning problem can be viewed as approximating an unknown target function $f:\mathcal{X}\rightarrow \mathcal{Y}$ by constructing a function $\hat{f}:\mathcal{X}\rightarrow \mathcal{Y}$ using a set of $k$ training examples $T=\{\left&amp;lt;X_i, Y_i\right&amp;gt; | i=1..k, X_i\in\mathcal{X}, Y_i=f(X_i)\}$. The function $\hat{f}$ is referred to as a model. The goal of machine learning is to construct the model in such a way that its results on $X\in\mathcal{X}\setminus T$ are close – according to some measure – to $f(X)$.</description></item><item><title>Datapalooza, or IBM's Land Grab</title><link>https://blog.mmakowski.com/technology/datapalooza-or-ibms-land-grab/</link><pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate><guid>https://blog.mmakowski.com/technology/datapalooza-or-ibms-land-grab/</guid><description>IBM Watson’s spectacular success in Jeopardy a couple years ago was widely reported and highlighted the fact that the company, not generally considered to be at the forefront of technological innovation for the past 15 years or so, is attempting to carve for itself a large slice of the big data/data science/machine learning/cognitive computing/whatever term is fashionable this week pie. I did not appreciate the scope of their foray into this space until the Datapalooza Mashup event today.</description></item></channel></rss>