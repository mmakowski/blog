<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Precision confidence interval in the presence of unreliable labels | Maciek's blog</title><link rel=stylesheet href=/blog/css/style.css><link rel=stylesheet href=/blog/css/fonts.css></head><body><nav><ul class=menu><li><a href=/blog/technology/>Tech</a></li><li><a href=/blog/travel/>Travel</a></li><li><a href=/blog/cooking/>Cook</a></li></ul><hr></nav><div class=article-meta><h1><span class=title>Precision confidence interval in the presence of unreliable labels</span></h1></div><main><p>Consider a binary classifier that produced the following counts of true positives (TP) and false positives (FP) on test data.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>tp_observed <span style=color:#000;font-weight:700>=</span> <span style=color:#099>5285</span>
</span></span><span style=display:flex><span>fp_observed <span style=color:#000;font-weight:700>=</span> <span style=color:#099>3184</span>
</span></span></code></pre></div><p>We would like to know the 95% confidence interval for precision metric of this classifier. <a href=https://pdfs.semanticscholar.org/e399/9a46cb8aaf71131a77670da5c5c113aad01d.pdf>Goutte and Gaussier</a> showed that precision follows the Beta distribution with the counts of TPs and FPs as parameters, adjusted for prior. We will use uniform prior, $Beta(1,1)$.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>pymc3</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>pm</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>with</span> pm<span style=color:#000;font-weight:700>.</span>Model() <span style=color:#000;font-weight:700>as</span> model:
</span></span><span style=display:flex><span>    precision_reliable <span style=color:#000;font-weight:700>=</span> pm<span style=color:#000;font-weight:700>.</span>Beta(<span style=color:#d14>&#39;precision_reliable&#39;</span>, tp_observed <span style=color:#000;font-weight:700>+</span> <span style=color:#099>1</span>, fp_observed <span style=color:#000;font-weight:700>+</span> <span style=color:#099>1</span>)
</span></span></code></pre></div><p>The distribution and 95% confidence interval can be plotted by sampling this variable.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>%</span>matplotlib inline
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>from</span> <span style=color:#555>IPython.core.pylabtools</span> <span style=color:#000;font-weight:700>import</span> figsize
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>matplotlib.pyplot</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>plt</span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>numpy</span> <span style=color:#000;font-weight:700>as</span> <span style=color:#555>np</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>plot_dist</span>(variable, confidence_level_percent<span style=color:#000;font-weight:700>=</span><span style=color:#099>95</span>):
</span></span><span style=display:flex><span>    figsize(<span style=color:#099>16</span>, <span style=color:#099>4</span>)
</span></span><span style=display:flex><span>    samples <span style=color:#000;font-weight:700>=</span> variable<span style=color:#000;font-weight:700>.</span>random(size<span style=color:#000;font-weight:700>=</span><span style=color:#099>100000</span>)
</span></span><span style=display:flex><span>    _, ax <span style=color:#000;font-weight:700>=</span> plt<span style=color:#000;font-weight:700>.</span>subplots()
</span></span><span style=display:flex><span>    plt<span style=color:#000;font-weight:700>.</span>hist(samples, bins<span style=color:#000;font-weight:700>=</span><span style=color:#099>100</span>, normed<span style=color:#000;font-weight:700>=</span><span style=color:#000;font-weight:700>True</span>, histtype<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;stepfilled&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#000;font-weight:700>.</span>title(<span style=color:#d14>&#34;Posterior distribution for </span><span style=color:#d14>%s</span><span style=color:#d14>&#34;</span> <span style=color:#000;font-weight:700>%</span> variable<span style=color:#000;font-weight:700>.</span>name)
</span></span><span style=display:flex><span>    plt<span style=color:#000;font-weight:700>.</span>xlim(<span style=color:#099>0</span>, <span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    conf_interval_min <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>percentile(samples, (<span style=color:#099>100</span><span style=color:#000;font-weight:700>-</span>confidence_level_percent) <span style=color:#000;font-weight:700>/</span> <span style=color:#099>2</span>)
</span></span><span style=display:flex><span>    conf_interval_max <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>percentile(samples, confidence_level_percent  <span style=color:#000;font-weight:700>+</span>  (<span style=color:#099>100</span><span style=color:#000;font-weight:700>-</span>confidence_level_percent) <span style=color:#000;font-weight:700>/</span> <span style=color:#099>2</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>axvline(x<span style=color:#000;font-weight:700>=</span>conf_interval_min, ymin<span style=color:#000;font-weight:700>=</span><span style=color:#099>0</span>, ymax<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, color<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;r&#39;</span>, linewidth<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>text(x<span style=color:#000;font-weight:700>=</span>conf_interval_min<span style=color:#000;font-weight:700>-</span><span style=color:#099>0.04</span>, y<span style=color:#000;font-weight:700>=</span>ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>/</span><span style=color:#099>2</span>, s<span style=color:#000;font-weight:700>=</span><span style=color:#0086b3>round</span>(conf_interval_min, <span style=color:#099>3</span>), color<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;r&#39;</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>axvline(x<span style=color:#000;font-weight:700>=</span>conf_interval_max, ymin<span style=color:#000;font-weight:700>=</span><span style=color:#099>0</span>, ymax<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>, color<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;r&#39;</span>, linewidth<span style=color:#000;font-weight:700>=</span><span style=color:#099>1</span>)
</span></span><span style=display:flex><span>    ax<span style=color:#000;font-weight:700>.</span>text(x<span style=color:#000;font-weight:700>=</span>conf_interval_max<span style=color:#000;font-weight:700>+</span><span style=color:#099>0.01</span>, y<span style=color:#000;font-weight:700>=</span>ax<span style=color:#000;font-weight:700>.</span>get_ylim()[<span style=color:#099>1</span>]<span style=color:#000;font-weight:700>/</span><span style=color:#099>2</span>, s<span style=color:#000;font-weight:700>=</span><span style=color:#0086b3>round</span>(conf_interval_max, <span style=color:#099>3</span>), color<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#39;r&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_dist(precision_reliable)
</span></span></code></pre></div><p><img src=01-unreliable-labels_5_0.png alt="posterior distribution of precision_reliable, 95% confidence interval is 0.614-0.634"></p><p>We suspected the labels used to identify positives and negatives in the test set were inaccurate, so we reviewed randomly selected observed TPs and FPs, 100 from each group, and counted how many of them had incorrect labels.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>reviewed_tp <span style=color:#000;font-weight:700>=</span> <span style=color:#099>100</span>
</span></span><span style=display:flex><span>mislabelled_tp <span style=color:#000;font-weight:700>=</span> <span style=color:#099>7</span>
</span></span><span style=display:flex><span>reviewed_fp <span style=color:#000;font-weight:700>=</span> <span style=color:#099>100</span>
</span></span><span style=display:flex><span>mislabelled_fp <span style=color:#000;font-weight:700>=</span> <span style=color:#099>31</span>
</span></span></code></pre></div><p>How can we account for the mislabelling when calculating the posterior of precision?</p><p>One way would be to consider the true mislabelling rates to follow a certain probability distribution, and caculate the posterior based on the available evidence. Beta distribution again looks like a good candidate, seeing that it can be used to describe the probability of success – “success” meaning a given example being mislabelled, in our case. Again, we will assume uninformative prior, i.e. $Beta(1,1)$.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>def</span> <span style=color:#900;font-weight:700>precision_with_unreliable_labels</span>(prior_tp<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>1</span>,<span style=color:#099>1</span>), prior_fp<span style=color:#000;font-weight:700>=</span>(<span style=color:#099>1</span>,<span style=color:#099>1</span>)):
</span></span><span style=display:flex><span>    <span style=color:#000;font-weight:700>with</span> pm<span style=color:#000;font-weight:700>.</span>Model() <span style=color:#000;font-weight:700>as</span> model:
</span></span><span style=display:flex><span>        mislabel_rate_tp <span style=color:#000;font-weight:700>=</span> pm<span style=color:#000;font-weight:700>.</span>Beta(<span style=color:#d14>&#39;mislabel_rate_tp&#39;</span>, mislabelled_tp <span style=color:#000;font-weight:700>+</span> prior_tp[<span style=color:#099>0</span>], reviewed_tp <span style=color:#000;font-weight:700>-</span> mislabelled_tp <span style=color:#000;font-weight:700>+</span> prior_tp[<span style=color:#099>1</span>])
</span></span><span style=display:flex><span>        mislabel_rate_fp <span style=color:#000;font-weight:700>=</span> pm<span style=color:#000;font-weight:700>.</span>Beta(<span style=color:#d14>&#39;mislabel_rate_fp&#39;</span>, mislabelled_fp <span style=color:#000;font-weight:700>+</span> prior_fp[<span style=color:#099>0</span>], reviewed_fp <span style=color:#000;font-weight:700>-</span> mislabelled_fp <span style=color:#000;font-weight:700>+</span> prior_fp[<span style=color:#099>1</span>])
</span></span><span style=display:flex><span>        tp_actual <span style=color:#000;font-weight:700>=</span> tp_observed <span style=color:#000;font-weight:700>*</span> (<span style=color:#099>1</span><span style=color:#000;font-weight:700>-</span>mislabel_rate_tp) <span style=color:#000;font-weight:700>+</span> fp_observed <span style=color:#000;font-weight:700>*</span> mislabel_rate_fp
</span></span><span style=display:flex><span>        fp_actual <span style=color:#000;font-weight:700>=</span> fp_observed <span style=color:#000;font-weight:700>*</span> (<span style=color:#099>1</span><span style=color:#000;font-weight:700>-</span>mislabel_rate_fp) <span style=color:#000;font-weight:700>+</span> tp_observed <span style=color:#000;font-weight:700>*</span> mislabel_rate_tp
</span></span><span style=display:flex><span>        <span style=color:#000;font-weight:700>return</span> pm<span style=color:#000;font-weight:700>.</span>Beta(<span style=color:#d14>&#39;precision_unreliable&#39;</span>, tp_actual <span style=color:#000;font-weight:700>+</span> <span style=color:#099>1</span>, fp_actual <span style=color:#000;font-weight:700>+</span> <span style=color:#099>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_dist(precision_with_unreliable_labels())
</span></span></code></pre></div><p><img src=01-unreliable-labels_9_0.png alt="posterior distribution of precision_unreliable, 95% confidence interval is 0.644-0.74"></p><p>In reality we probably have some prior expectation regarding the mislabelling rates. For example, we might believe it likely that less than half of the examples is mislabelled, or that positives are more likely to be incorrectly labelled as negatives than vice versa. Those beliefs can be encoded by the priors used for mislabelling rates.</p><p>Say, before reviewing the samples we were very certain the proportion of mislabelled FPs is small, but we were not so sure about the TPs. This can be modelled as appropriate shape parameters for the prior Beta distributions.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000;font-weight:700>import</span> <span style=color:#555>scipy.stats</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>prior_tp <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>1.4</span>, <span style=color:#099>1.8</span>)
</span></span><span style=display:flex><span>prior_fp <span style=color:#000;font-weight:700>=</span> (<span style=color:#099>1</span>, <span style=color:#099>10</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>x <span style=color:#000;font-weight:700>=</span> np<span style=color:#000;font-weight:700>.</span>linspace(<span style=color:#099>0</span>, <span style=color:#099>1.0</span>, <span style=color:#099>100</span>)
</span></span><span style=display:flex><span>plt<span style=color:#000;font-weight:700>.</span>plot(x, scipy<span style=color:#000;font-weight:700>.</span>stats<span style=color:#000;font-weight:700>.</span>beta<span style=color:#000;font-weight:700>.</span>pdf(x, <span style=color:#000;font-weight:700>*</span>prior_tp), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;TP mislabelling prior&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#000;font-weight:700>.</span>plot(x, scipy<span style=color:#000;font-weight:700>.</span>stats<span style=color:#000;font-weight:700>.</span>beta<span style=color:#000;font-weight:700>.</span>pdf(x, <span style=color:#000;font-weight:700>*</span>prior_fp), label<span style=color:#000;font-weight:700>=</span><span style=color:#d14>&#34;FP mislabelling prior&#34;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#000;font-weight:700>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#000;font-weight:700>.</span>show()
</span></span></code></pre></div><p><img src=01-unreliable-labels_11_0.png alt="prior Beta distributions for mislabelling rates, FP fast converging to 0, TP closer to uniform"></p><p>How does it affect the precision confidence interval?</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>plot_dist(precision_with_unreliable_labels(prior_tp, prior_fp))
</span></span></code></pre></div><p><img src=01-unreliable-labels_13_0.png alt="posterior distribution of precision_unreliable with altered priors, 95% confidence interval is 0.633-0.726"></p><ul><li><a href=http://nbviewer.jupyter.org/github/mmakowski/datasci/blob/master/01-unreliable-labels.ipynb>source notebook</a></li></ul></main><p class=date>07/08/2018</p><footer><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><hr>© Maciek Makowski 2010 &ndash; 2022. Content licensed under <a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a></footer></body></html>